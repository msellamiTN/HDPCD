Create a folder for storing imported files on hdfs
	hadoop fs -mkdir -p /user/hive_demos/data_import

Put deckofcards.txt to the above location
	hadoop fs -put /root/deckofcards.txt /user/hive_demos/data_import

1)Create Database :->

CREATE DATABASE IF NOT EXISTS cards;

USE cards;

2) CREATE TABLE :->

CREATE TABLE deck_of_cards (
COLOR string,
SUIT string,
PIP string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘|’
STORED AS TEXTFILE;

3) Load the Table with data :->

LOAD DATA LOCAL INPATH ‘/root/deckofcards.txt’ INTO TABLE deck_of_cards;

4) Display/Set Hive Params :->
   
   set mapreduce.job.reduces; //DISPLAY
   set mapreduce.job.reduces=2; //SET

5) Important Commands :->
   show databases;
   use {database_name};
   show tables;
   describe {table_name};
   describe formatted {table_name};

6) Simple Queries :->

   select * from departments;
   select count(*) from orders;
   select * from orders limit 10;

7) Use all Clauses :->
   SELECT order_status, count(1) FROM orders WHERE order_date = ‘2013-12-14 00:00:00.0’
   GROUP BY order_status ORDER BY order_status;

   —-Get number of complete orders for each date before ‘2013-12-14 00:00:00.0’
   SELECT order_date, COUNT(1) FROM orders
   WHERE order_date <= ‘2013-12-14 00:00:00.0’ AND order_status = ’COMPLETE’
   GROUP BY order_date
   ORDER BY order_date;

   —-Get number of pending orders for each date for the month 0f 2013 December
   SELECT order_date, COUNT(1) FROM orders
   WHERE order_date LIKE ‘2013-12%’ 
   AND order_status IN (’PENDING’,’PENDING_PAYMENT’,’PAYMENT_REVIEW’,’ON_HOLD’)
   GROUP BY order_date
   ORDER BY order_date;

8) Create Managed Table :->
   
   —-Create hdfs directory from sqoop commabd
   sqoop import-all-tables \
   --connect jdbc:mysql://localhost:3306/retail_db \
   —-username retail_dba
   --password hadoop \
   --warehouse-dir=/apps/hive/warehouse/retail_stage.db
   —-driver com.mysql.jdbc.Driver
 
   —-Create a hive database on top of the hdfs directory 
   create database retail_stage;

   —-Create table
   CREATE TABLE orders_demo (
   order_id INT,
   order_date DATE,order_customer_id INT,
   order_status VARCHAR(30))
   ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
   STORED AS TEXTFILE;

Copy file from HDFS to HDFS :->
hadoop distcp /user/hive_demo/deckofcards.txt /user/hive_Demo/cards/deckofcards.txt

9) Create External Table :->
   
   CREATE DATABASE cards;
   CREATE EXTERNAL TABLE deck_of_cards_external (
   color string,
   suit string,
   pip string)
   ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘|’
   STORED AS TEXTFILE
   LOCATION ‘/user/hive_demo/cards’;

10) Prepare Data :->
    AFTER Sqoop Import as Avrao files move all .avsc files to HDFS location
    hadoop fs -put *.avsc /user/Avro_Files
    
    CREATE EXTERNAL TABLES :->
    CREATE EXTERNAL TABLE categories
    ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.avro.AvroSerDe’
    STORED AS AVRO
    LOCATION ‘hdfs:///apps/hive/warehouse/retail_stage.db/categories’
    TBLPROPERTIES (‘avrò.schema.url’=‘hdfs://sandbox.hortonworks.com/user/Avro_Files/categories.avsc’

    CREATE EXTERNAL TABLE customers
    ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.avro.AvroSerDe’
    STORED AS AVRO
    LOCATION ‘hdfs:///apps/hive/warehouse/retail_stage.db/customers’
    TBLPROPERTIES (‘avrò.schema.url’=‘hdfs://sandbox.hortonworks.com/user/Avro_Files/customers.avsc’

    CREATE EXTERNAL TABLE departments
    ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.avro.AvroSerDe’
    STORED AS AVRO
    LOCATION ‘hdfs:///apps/hive/warehouse/retail_stage.db/departments’
    TBLPROPERTIES (‘avrò.schema.url’=‘hdfs://sandbox.hortonworks.com/user/Avro_Files/departments.avsc’

    CREATE EXTERNAL TABLE order_items
    ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.avro.AvroSerDe’
    STORED AS AVRO
    LOCATION ‘hdfs:///apps/hive/warehouse/retail_stage.db/order_items’
    TBLPROPERTIES (‘avrò.schema.url’=‘hdfs://sandbox.hortonworks.com/user/Avro_Files/corder_items.avsc’

    CREATE EXTERNAL TABLE orders
    ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.avro.AvroSerDe’
    STORED AS AVRO
    LOCATION ‘hdfs:///apps/hive/warehouse/retail_stage.db/orders’
    TBLPROPERTIES (‘avrò.schema.url’=‘hdfs://sandbox.hortonworks.com/user/Avro_Files/orders.avsc’

    CREATE EXTERNAL TABLE products
    ROW FORMAT SERDE ‘org.apache.hadoop.hive.serde2.avro.AvroSerDe’
    STORED AS AVRO
    LOCATION ‘hdfs:///apps/hive/warehouse/retail_stage.db/products’
    TBLPROPERTIES (‘avrò.schema.url’=‘hdfs://sandbox.hortonworks.com/user/Avro_Files/products.avsc’

    CREATE PARTITION TABLE ->

11) Bucketed Table :->

12) CTAS AND ORC File Format :->

13) Field Delimiters :->

14) Load Data To Hive from Local File System and HDFS :->
 
    LOAD DATA INPATH ‘/root/deckofcards.txt’ INTO TABLE deck_of_cards;

    LOAD DATA LOCAL INPATH ‘/root/deckofcards.txt’ OVERWRITE INTO TABLE deck_of_cards;

15) 


   
    